{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization Techniques Contd.\n",
    "\n",
    "## 3. Automated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Automated Hyperparameter Tuning can be done by using techniques such as\n",
    "\n",
    "- Bayesian Optimization\n",
    "- Gradient Descent\n",
    "- Evolutionary Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Bayesian optimization uses probability to find the minimum of a function. \n",
    "    2. The final aim is to find the input value to a function which can gives us the lowest possible output value.\n",
    "    3. It usually performs better than random,grid and manual search providing better performance in the testing phase and reduced optimization time. \n",
    "    4. In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters to the function fmin.\n",
    "\n",
    "- Objective Function = \n",
    "    `defines the loss function to minimize.`\n",
    "- Domain Space = \n",
    "    `defines the range of input values to test (in Bayesian Optimization this space creates a probability distribution for each of the used Hyperparameters).`\n",
    "- Optimization Algorithm = \n",
    "    `defines the search algorithm to use to select the best input values to use in each new iteration.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0             72             35        0  33.6   \n",
       "1            1     85.0             66             29        0  26.6   \n",
       "2            8    183.0             64              0        0  23.3   \n",
       "3            1     89.0             66             23       94  28.1   \n",
       "4            0    137.0             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['Glucose']=np.where(df['Glucose']==0,df['Glucose'].median(),df['Glucose'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Independent And Dependent features\n",
    "X=df.drop('Outcome',axis=1)\n",
    "y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.4-py2.py3-none-any.whl (964 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (4.44.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\deepak\\appdata\\roaming\\python\\python37\\site-packages (from hyperopt) (1.12.0)\n",
      "Requirement already satisfied: future in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperopt) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Installing collected packages: hyperopt\n",
      "Successfully installed hyperopt-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
    "    }\n",
    "\n",
    "\n",
    "## hp.choice to select between a list\n",
    "## hp.quniform to select between a range of no having saome equal\n",
    "## hp.uniform to slecect btween floating no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': <hyperopt.pyll.base.Apply at 0x2a16c279a88>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x2a16c279ec8>,\n",
       " 'max_features': <hyperopt.pyll.base.Apply at 0x2a16c282488>,\n",
       " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x2a16c282848>,\n",
       " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x2a16c282c08>,\n",
       " 'n_estimators': <hyperopt.pyll.base.Apply at 0x2a16c2844c8>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = space['n_estimators'], \n",
    "                                 )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 80/80 [11:16<00:00,  8.46s/trial, best loss: -0.7622684259629482]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0,\n",
       " 'max_depth': 90.0,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 0.014039745879919538,\n",
       " 'min_samples_split': 0.10785280990155477,\n",
       " 'n_estimators': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trials)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "log2\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "## Since the above result in in key val pairs the below is done to get the vlue from key val\n",
    "\n",
    "crit = {0: 'entropy', 1: 'gini'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200,5:1300,6:1500}\n",
    "\n",
    "\n",
    "print(crit[best['criterion']])\n",
    "print(feat[best['max_features']])\n",
    "print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- confusion_matrix -------------------------\n",
      "[[97 10]\n",
      " [22 25]]\n",
      "---------------------- accuracy_score -------------------------\n",
      "0.7922077922077922\n",
      "---------------------- classification_report -------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       107\n",
      "           1       0.71      0.53      0.61        47\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.76      0.72      0.73       154\n",
      "weighted avg       0.78      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]).fit(X_train,y_train)\n",
    "predictionforest = trainedforest.predict(X_test)\n",
    "\n",
    "print('---------------------- confusion_matrix -------------------------')\n",
    "print(confusion_matrix(y_test,predictionforest))\n",
    "\n",
    "print('---------------------- accuracy_score -------------------------')\n",
    "print(accuracy_score(y_test,predictionforest))\n",
    "\n",
    "print('---------------------- classification_report -------------------------')\n",
    "print(classification_report(y_test,predictionforest))\n",
    "acc5 = accuracy_score(y_test,predictionforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922077922077922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithms\n",
    "    Genetic Algorithms tries to apply natural selection mechanisms to Machine Learning contexts.\n",
    "\n",
    "1. Let's immagine we create a population of N Machine Learning models with some predifined Hyperparameters. \n",
    "2. We can then calculate the accuracy of each model and decide to keep just half of the models (the ones that performs best). \n",
    "3. We can now generate some offsprings having similar Hyperparameters to the ones of the best models so that go get again a population of N models. \n",
    "4. At this point we can again calculate the accuracy of each model and repeate the cycle for a defined number of generations. \n",
    "5. In this way, just the best models will survive at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.11.5-py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (4.44.1)\n",
      "Collecting deap>=1.2\n",
      "  Downloading deap-1.3.1-cp37-cp37m-win_amd64.whl (108 kB)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (1.18.1)\n",
      "Collecting update-checker>=0.16\n",
      "  Downloading update_checker-0.17-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (1.0.3)\n",
      "Collecting stopit>=1.1.1\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2019.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deepak\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->tpot) (1.12.0)\n",
      "Building wheels for collected packages: stopit\n",
      "  Building wheel for stopit (setup.py): started\n",
      "  Building wheel for stopit (setup.py): finished with status 'done'\n",
      "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11959 sha256=d91aef9c7180479112cd743c11a393594664e025ad74b61ab0817c3df2eba800\n",
      "  Stored in directory: c:\\users\\deepak\\appdata\\local\\pip\\cache\\wheels\\e2\\d2\\79\\eaf81edb391e27c87f51b8ef901ecc85a5363dc96b8b8d71e3\n",
      "Successfully built stopit\n",
      "Installing collected packages: deap, update-checker, stopit, tpot\n",
      "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.5 update-checker-0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot\n",
    "\n",
    "## needs tensflow to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=84.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7606209150326797\n",
      "Generation 2 - Current best internal CV score: 0.7606209150326797\n",
      "Generation 3 - Current best internal CV score: 0.7622336813513284\n",
      "Generation 4 - Current best internal CV score: 0.7622336813513284\n",
      "Generation 5 - Current best internal CV score: 0.7622336813513284\n",
      "Best pipeline: RandomForestClassifier(RandomForestClassifier(input_matrix, criterion=gini, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=2000), criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['entropy',\n",
       "                                                                                      'gini'],\n",
       "                                                                        'max_depth': [10,\n",
       "                                                                                      120,\n",
       "                                                                                      230,\n",
       "                                                                                      340,\n",
       "                                                                                      450,\n",
       "                                                                                      560,\n",
       "                                                                                      670,\n",
       "                                                                                      780,\n",
       "                                                                                      890,\n",
       "                                                                                      1000],\n",
       "                                                                        'max_features': ['auto',\n",
       "                                                                                         'sqrt',\n",
       "                                                                                         'log2'],\n",
       "                                                                        'min_samples_leaf': [1,\n",
       "                                                                                             2,\n",
       "                                                                                             4,\n",
       "                                                                                             6,\n",
       "                                                                                             8],\n",
       "                                                                        'min_samples_split': [2,\n",
       "                                                                                              5,\n",
       "                                                                                              10,\n",
       "                                                                                              14],\n",
       "                                                                        'n_estimators': [200,\n",
       "                                                                                         400,\n",
       "                                                                                         600,\n",
       "                                                                                         800,\n",
       "                                                                                         1000,\n",
       "                                                                                         1200,\n",
       "                                                                                         1400,\n",
       "                                                                                         1600,\n",
       "                                                                                         1800,\n",
       "                                                                                         2000]}},\n",
       "               crossover_rate=0.1, cv=4, disa...\n",
       "               early_stop=12, generations=5,\n",
       "               log_file=<ipykernel.iostream.OutStream object at 0x000002A1695EDF88>,\n",
       "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=1, offspring_size=12,\n",
       "               periodic_checkpoint_folder=None, population_size=24,\n",
       "               random_state=None, scoring='accuracy', subsample=1.0,\n",
       "               template=None, use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "\n",
    "tpot_classifier = TPOTClassifier(generations= 5, population_size= 24, offspring_size= 12,\n",
    "                                 verbosity= 2, early_stop= 12,\n",
    "                                 config_dict={'sklearn.ensemble.RandomForestClassifier': param}, \n",
    "                                 cv = 4, scoring = 'accuracy')\n",
    "tpot_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8376623376623377\n"
     ]
    }
   ],
   "source": [
    "accuracy = tpot_classifier.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
